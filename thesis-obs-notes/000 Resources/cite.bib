@inproceedings{undefined, 
keywords = {Generation,Sense Reasoning}, 
author = {D., Hwang, Jena and Chandra, Bhagavatula, and Le, Bras, Ronan and Jeff, Da, and Keisuke, Sakaguchi, and Antoine, Bosselut, and Yejin, Choi,}, 
title = {{(Comet-) Atomic 2020: On Symbolic and Neural Commonsense Knowledge Graphs}}, 
url = {https://ojs.aaai.org/index.php/AAAI/article/view/16792}, 
abstract = {{Recent years have brought about a renewed interest in commonsense representation and reasoning in the field of natural language understanding. The development of new commonsense knowledge graphs (CSKG) has been central to these advances as their diverse facts can be used and referenced by machine learning models for tackling new and challenging tasks. At the same time, there remain questions about the quality and coverage of these resources due to the massive scale required to comprehensively encompass general commonsense knowledge.In this work, we posit that manually constructed CSKGs will never achieve the coverage necessary to be applicable in all situations encountered by NLP agents. Therefore, we propose a new evaluation framework for testing the utility of KGs based on how effectively implicit knowledge representations can be learned from them.With this new goal, we propose Atomic 2020, a new CSKG of general-purpose commonsense knowledge containing knowledge that is not readily available in pretrained language models. We evaluate its properties in comparison with other leading CSKGs, performing the first large-scale pairwise study of commonsense knowledge resources. Next, we show that Atomic 2020 is better suited for training knowledge models that can generate accurate, representative knowledge for new, unseen entities and events. Finally, through human evaluation, we show that the few-shot performance of GPT-3 (175B parameters), while impressive, remains \textbackslashtextasciitilde12 absolute points lower than a BART-based knowledge model trained on Atomic 2020 despite using over 430x fewer parameters.}}, 
pages = {6384--6392}, 
volume = {35}
}
@article{undefined, 
title = {{Affect-LM: A Neural Language Model for Customizable Affective Text Generation}}, 
author = {Sayan, Ghosh, and Mathieu, Chollet, and Eugene, Laksana, and Louis-Philippe, Morency, and Stefan, Scherer,}, 
journal = {ACL 2017 - 55th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)}, 
url = {http://arxiv.org/abs/1704.06851}, 
abstract = {{Human verbal communication includes affective messages which are conveyed through use of emotionally colored words. There has been a lot of research in this direction but the problem of integrating state-of-the-art neural language models with affective information remains an area ripe for exploration. In this paper, we propose an extension to an LSTM (Long Short-Term Memory) language model for generating conversational text, conditioned on affect categories. Our proposed model, Affect-LM enables us to customize the degree of emotional content in generated sentences through an additional design parameter. Perception studies conducted using Amazon Mechanical Turk show that Affect-LM generates naturally looking emotional sentences without sacrificing grammatical correctness. Affect-LM also learns affect-discriminative word representations, and perplexity experiments show that additional affective information in conversational text can improve language model prediction.}}, 
year = {2017}, 
pages = {634--642}, 
volume = {1}
}
@inproceedings{undefined, 
author = {Ashish, Vaswani, and Noam, Shazeer, and Niki, Parmar, and Jakob, Uszkoreit, and Llion, Jones, and N., Gomez, Aidan and ≈Åukasz, Kaiser, and Illia, Polosukhin,}, 
title = {{Attention is all you need}}, 
abstract = {{The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.}}, 
volume = {2017-December}
}
@article{undefined, 
title = {{Attention Is All You Need}}, 
author = {Ashish, Vaswani, and Noam, Shazeer, and Niki, Parmar, and Jakob, Uszkoreit, and Llion, Jones, and N., Gomez, Aidan and Lukasz, Kaiser, and Illia, Polosukhin,}, 
journal = {Advances in Neural Information Processing Systems}, 
url = {https://arxiv.org/abs/1706.03762v5}, 
abstract = {{The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder-decoder configuration. The bestperforming models also connect the encoder and decoder through an attentionmechanism. We propose a new simple network architecture, the Transformer, basedsolely on attention mechanisms, dispensing with recurrence and convolutionsentirely. Experiments on two machine translation tasks show these models to besuperior in quality while being more parallelizable and requiring significantlyless time to train. Our model achieves 28.4 BLEU on the WMT 2014English-to-German translation task, improving over the existing best results,including ensembles by over 2 BLEU. On the WMT 2014 English-to-Frenchtranslation task, our model establishes a new single-model state-of-the-artBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fractionof the training costs of the best models from the literature. We show that theTransformer generalizes well to other tasks by applying it successfully toEnglish constituency parsing both with large and limited training data.}}, 
year = {2017}, 
pages = {5999--6009}, 
volume = {2017-December}
}
@article{undefined, 
title = {{Challenges in Detoxifying Language Models}}, 
author = {Johannes, Welbl, and Amelia, Glaese, and Jonathan, Uesato, and Sumanth, Dathathri, and John, Mellor, and Anne, Hendricks, Lisa and Kirsty, Anderson, and Pushmeet, Kohli, and Ben, Coppin, and Po-Sen, Huang,}, 
url = {https://arxiv.org/abs/2109.07445v1}, 
abstract = {{Large language models (LM) generate remarkably fluent text and can beefficiently adapted across NLP tasks. Measuring and guaranteeing the quality ofgenerated text in terms of safety is imperative for deploying LMs in the realworld; to this end, prior work often relies on automatic evaluation of LMtoxicity. We critically discuss this approach, evaluate several toxicitymitigation strategies with respect to both automatic and human evaluation, andanalyze consequences of toxicity mitigation in terms of model bias and LMquality. We demonstrate that while basic intervention strategies caneffectively optimize previously established automatic metrics on theRealToxicityPrompts dataset, this comes at the cost of reduced LM coverage forboth texts about, and dialects of, marginalized groups. Additionally, we findthat human raters often disagree with high automatic toxicity scores afterstrong toxicity reduction interventions -- highlighting further the nuancesinvolved in careful evaluation of LM toxicity.}}, 
year = {2021}
}
@inproceedings{undefined, 
author = {Antoine, Bosselut, and Hannah, Rashkin, and Maarten, Sap, and Chaitanya, Malaviya, and Asli, Celikyilmaz, and Yejin, Choi,}, 
title = {{CoMET: Commonsense transformers for automatic knowledge graph construction}}, 
abstract = {{We present the first comprehensive study on automatic knowledge base construction for two prevalent commonsense knowledge graphs: ATOMIC (Sap et al., 2019) and ConceptNet (Speer et al., 2017). Contrary to many conventional KBs that store knowledge with canonical templates, commonsense KBs only store loosely structured open-text descriptions of knowledge. We posit that an important step toward automatic commonsense completion is the development of generative models of commonsense knowledge, and propose COMmonsEnse Transformers (COMET) that learn to generate rich and diverse commonsense descriptions in natural language. Despite the challenges of commonsense modeling, our investigation reveals promising results when implicit knowledge from deep pre-trained language models is transferred to generate explicit knowledge in commonsense knowledge graphs. Empirical results demonstrate that COMET is able to generate novel knowledge that humans rate as high quality, with up to 77.5\% (ATOMIC) and 91.7\% (ConceptNet) precision at top 1, which approaches human performance for these resources. Our findings suggest that using generative commonsense models for automatic commonsense KB completion could soon be a plausible alternative to extractive methods.}}, 
pages = {4762--4779}, 
publisher = {Association for Computational Linguistics (ACL)}
}
@article{undefined, 
title = {{Controlling Linguistic Style Aspects in Neural Language Generation}}, 
author = {Jessica, Ficler, and Yoav, Goldberg,}, 
url = {https://arxiv.org/abs/1707.02633v1}, 
abstract = {{Most work on neural natural language generation (NNLG) focus on controllingthe content of the generated text. We experiment with controlling severalstylistic aspects of the generated text, in addition to its content. The methodis based on conditioned RNN language model, where the desired content as wellas the stylistic parameters serve as conditioning contexts. We demonstrate theapproach on the movie reviews domain and show that it is successful ingenerating coherent sentences corresponding to the required linguistic styleand content.}}, 
year = {2017}, 
pages = {94--104}
}
@article{10.18653/v1/d16-1140, 
year = {2016}, 
title = {{Controlling Output Length in Neural Encoder-Decoders}}, 
author = {Yuta, Kikuchi, and Graham, Neubig, and Ryohei, Sasano, and Hiroya, Takamura, and Manabu, Okumura,}, 
journal = {EMNLP 2016 - Conference on Empirical Methods in Natural Language Processing, Proceedings}, 
doi = {10.18653/v1/d16-1140}, 
url = {https://aclanthology.org/D16-1140}, 
abstract = {{Neural encoder-decoder models have shown great success in many sequence generation tasks. However, previous work has not investigated situations in which we would like to control the length of encoder-decoder outputs. This capability is crucial for applications such as text summarization, in which we have to generate concise summaries with a desired length. In this paper, we propose methods for controlling the output sequence length for neural encoder-decoder models: two decoding-based methods and two learning-based methods.1 Results show that our learning-based methods have the capability to control length without degrading summary quality in a summarization task.}}, 
pages = {1328--1338}
}
@article{undefined, 
title = {{CTRL: A Conditional Transformer Language Model for Controllable Generation}}, 
author = {Shirish, Keskar, Nitish and Bryan, McCann, and R., Varshney, Lav and Caiming, Xiong, and Richard, Socher,}, 
url = {http://arxiv.org/abs/1909.05858}, 
abstract = {{Large-scale language models show promising text generation capabilities, but users cannot easily control particular aspects of the generated text. We release CTRL, a 1.63 billion-parameter conditional transformer language model, trained to condition on control codes that govern style, content, and task-specific behavior. Control codes were derived from structure that naturally co-occurs with raw text, preserving the advantages of unsupervised learning while providing more explicit control over text generation. These codes also allow CTRL to predict which parts of the training data are most likely given a sequence. This provides a potential method for analyzing large amounts of data via model-based source attribution. We have released multiple full-sized, pretrained versions of CTRL at https://github.com/salesforce/ctrl.}}, 
year = {2019}
}
@inproceedings{10.1145/3442381.3449981, 
year = {2021}, 
keywords = {Curriculum learning,Cycle-consistent generative adversarial network,Domain adaptation,Multiple sources,Sentiment analysis}, 
author = {Sicheng, Zhao, and Yang, Xiao, and Jiang, Guo, and Xiangyu, Yue, and Jufeng, Yang, and Ravi, Krishna, and Pengfei, Xu, and Kurt, Keutzer,}, 
title = {{Curriculum cycleGAN for textual sentiment domain adaptation with multiple sources}}, 
isbn = {9781450383127}, 
doi = {10.1145/3442381.3449981}, 
abstract = {{Sentiment analysis of user-generated reviews or comments on products and services in social networks can help enterprises to analyze the feedback from customers and take corresponding actions for improvement. To mitigate large-scale annotations on the target domain, domain adaptation (DA) provides an alternate solution by learning a transferable model from other labeled source domains. Existing multi-source domain adaptation (MDA) methods either fail to extract some discriminative features in the target domain that are related to sentiment, neglect the correlations of different sources and the distribution difference among different sub-domains even in the same source, or cannot reflect the varying optimal weighting during different training stages. In this paper, we propose a novel instance-level MDA framework, named curriculum cycle-consistent generative adversarial network (C-CycleGAN), to address the above issues. Specifically, C-CycleGAN consists of three components: (1) pre-trained text encoder which encodes textual input from different domains into a continuous representation space, (2) intermediate domain generator with curriculum instance-level adaptation which bridges the gap across source and target domains, and (3) task classifier trained on the intermediate domain for final sentiment classification. C-CycleGAN transfers source samples at instance-level to an intermediate domain that is closer to the target domain with sentiment semantics preserved and without losing discriminative features. Further, our dynamic instance-level weighting mechanisms can assign the optimal weights to different source samples in each training stage. We conduct extensive experiments on three benchmark datasets and achieve substantial gains over state-of-the-art DA approaches. Our source code is released at: https://github.com/WArushrush/Curriculum-CycleGAN.}}, 
pages = {541--552}, 
series = {Proceedings of the Web Conference 2021}, 
publisher = {Association for Computing Machinery, Inc}
}
@techreport{undefined, 
author = {Gr√©goire, Montavon, and Tu-berlinde, Sebastian Bach, and Hhifraunhoferde, Alexander Binder, and Alexander, Binder, and Wojciech, Samek, and M, Klaus-Robert, Hhifraunhoferde}, 
title = {{Deep Taylor Decomposition of Neural Networks}}, 
abstract = {{We summarize the main concepts behind a recently proposed method for explaining neural network predictions called deep Taylor decomposition. For conciseness, we only present the case of simple neural networks of ReLU neurons organized in a directed acyclic graph. More struc-tured networks with special layers are discussed in the original paper (Montavon et al., 2015).}}
}
@article{undefined, 
title = {{Delete, Retrieve, Generate: A Simple Approach to Sentiment and Style Transfer}}, 
author = {Juncen, Li, and Robin, Jia, and He, He, and Percy, Liang,}, 
journal = {NAACL HLT 2018 - 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Conference}, 
url = {https://arxiv.org/abs/1804.06437v1}, 
abstract = {{We consider the task of text attribute transfer: transforming a sentence toalter a specific attribute (e.g., sentiment) while preserving itsattribute-independent content (e.g., changing "screen is just the right size"to "screen is too small"). Our training data includes only sentences labeledwith their attribute (e.g., positive or negative), but not pairs of sentencesthat differ only in their attributes, so we must learn to disentangleattributes from attribute-independent content in an unsupervised way. Previouswork using adversarial methods has struggled to produce high-quality outputs.In this paper, we propose simpler methods motivated by the observation thattext attributes are often marked by distinctive phrases (e.g., "too small").Our strongest method extracts content words by deleting phrases associated withthe sentence's original attribute value, retrieves new phrases associated withthe target attribute, and uses a neural model to fluently combine these into afinal output. On human evaluation, our best method generates grammatical andappropriate responses on 22\% more inputs than the best previous system,averaged over three attribute transfer datasets: altering sentiment of reviewson Yelp, altering sentiment of reviews on Amazon, and altering image captionsto be more romantic or humorous.}}, 
year = {2018}, 
pages = {1865--1874}, 
volume = {1}
}
@inproceedings{undefined, 
author = {Yangfeng, Ji, and Chenhao, Tan, and Sebastian, Martschat, and Yejin, Choi, and A., Smith, Noah}, 
title = {{Dynamic entity representations in neural language models}}, 
abstract = {{Understanding a long document requires tracking how entities are introduced and evolve over time. We present a new type of language model, ENTITYNLM, that can explicitly model entities, dynamically update their representations, and contextually generate their mentions. Our model is generative and flexible; it can model an arbitrary number of entities in context while generating each entity mention at an arbitrary length. In addition, it can be used for several different tasks such as language modeling, coreference resolution, and entity prediction. Experimental results with all these tasks demonstrate that our model consistently outperforms strong baselines and prior work.}}, 
pages = {1830--1839}, 
publisher = {Association for Computational Linguistics (ACL)}
}
@inproceedings{undefined, 
author = {Bhanu, Prakash, and Reddy, Guda, and Adobe, Research, and Aparna, Garimella, and Niyati, Chhaya,}, 
title = {{EMPATHBERT: A BERT-based Framework for Demographic-aware Empathy Prediction}}, 
url = {https://u.cs.biu.ac.il/}, 
abstract = {{Affect preferences vary with user demograph-ics, and tapping into demographic information provides important cues about the users' language preferences. In this paper, we utilize the user demographics, and propose EMPATH-BERT, a demographic-aware framework for empathy prediction based on BERT. Through several comparative experiments, we show that EMPATHBERT surpasses traditional machine learning and deep learning models, and illustrate the importance of user demograph-ics to predict empathy and distress in user responses to stimulative news articles. We also highlight the importance of affect information in the responses by developing affect-aware models to predict user demographic attributes.}}, 
pages = {3072--3079}
}
@article{undefined, 
title = {{Fine-Tuning Language Models from Human Preferences}}, 
author = {M., Ziegler, Daniel and Nisan, Stiennon, and Jeffrey, Wu, and B., Brown, Tom and Alec, Radford, and Dario, Amodei, and Paul, Christiano, and Geoffrey, Irving,}, 
url = {http://arxiv.org/abs/1909.08593}, 
abstract = {{Reward learning enables the application of reinforcement learning (RL) to tasks where reward is defined by human judgment, building a model of reward by asking humans questions. Most work on reward learning has used simulated environments, but complex information about values is often expressed in natural language, and we believe reward learning for language is a key to making RL practical and safe for real-world tasks. In this paper, we build on advances in generative pretraining of language models to apply reward learning to four natural language tasks: continuing text with positive sentiment or physically descriptive language, and summarization tasks on the TL;DR and CNN/Daily Mail datasets. For stylistic continuation we achieve good results with only 5,000 comparisons evaluated by humans. For summarization, models trained with 60,000 comparisons copy whole sentences from the input but skip irrelevant preamble; this leads to reasonable ROUGE scores and very good performance according to our human labelers, but may be exploiting the fact that labelers rely on simple heuristics.}}, 
year = {2019}
}
@article{undefined, 
title = {{Generating More Interesting Responses in Neural Conversation Models with Distributional Constraints}}, 
author = {Ashutosh, Baheti, and Alan, Ritter, and Jiwei, Li, and Bill, Dolan,}, 
journal = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018}, 
url = {https://arxiv.org/abs/1809.01215v1}, 
abstract = {{Neural conversation models tend to generate safe, generic responses for mostinputs. This is due to the limitations of likelihood-based decoding objectivesin generation tasks with diverse outputs, such as conversation. To address thischallenge, we propose a simple yet effective approach for incorporating sideinformation in the form of distributional constraints over the generatedresponses. We propose two constraints that help generate more content richresponses that are based on a model of syntax and topics (Griffiths et al.,2005) and semantic similarity (Arora et al., 2016). We evaluate our approachagainst a variety of competitive baselines, using both automatic metrics andhuman judgments, showing that our proposed approach generates responses thatare much less generic without sacrificing plausibility. A working demo of ourcode can be found at https://github.com/abaheti95/DC-NeuralConversation.}}, 
year = {2018}, 
pages = {3970--3980}
}
@inproceedings{undefined, 
author = {Nasrin, Mostafazadeh, and Aditya, Kalyanpur, and Lori, Moon, and David, Buchanan, and Lauren, Berkowitz, and Or, Biran, and Jennifer, Chu-Carroll,}, 
title = {{GLUCOSE: GeneraLized and COntextualized Story Explanations}}, 
abstract = {{When humans read or listen, they make implicit commonsense inferences that frame their understanding of what happened and why. As a step toward AI systems that can build similar mental models, we introduce GLUCOSE, a large-scale dataset of implicit commonsense causal knowledge, encoded as causal mini-theories about the world, each grounded in a narrative context. To construct GLUCOSE, we drew on cognitive psychology to identify ten dimensions of causal explanation, focus-ing on events, states, motivations, and emotions. Each GLUCOSE entry includes a story-specific causal statement paired with an inference rule generalized from the statement. This paper details two concrete contributions. First, we present our platform for effectively crowd-sourcing GLUCOSE data at scale, which uses semi-structured templates to elicit causal explanations. Using this platform, we collected a total ofÀú670KofÀú670K specific statements and general rules that capture implicit commonsense knowledge about everyday situations. Second, we show that existing knowledge resources and pretrained language models do not include or readily predict GLUCOSE's rich inferential content. However, when state-of-the-art neural models are trained on this knowledge, they can start to make commonsense inferences on unseen stories that match humans' mental models .}}, 
pages = {4569--4586}
}
@inproceedings{undefined, 
author = {Lishan, Huang, and Zheng, Ye, and Jinghui, Qin, and Liang, Lin, and Xiaodan, Liang,}, 
title = {{GRADE: Automatic Graph-Enhanced Coherence Metric for Evaluating Open-Domain Dialogue Systems}}, 
abstract = {{Automatically evaluating dialogue coherence is a challenging but high-demand ability for developing high-quality open-domain dialogue systems. However, current evaluation met-rics consider only surface features or utterance-level semantics, without explicitly considering the fine-grained topic transition dynamics of dialogue flows. Here, we first consider that the graph structure constituted with topics in a dialogue can accurately depict the underlying communication logic, which is a more natural way to produce persuasive metrics. Capitalized on the topic-level dialogue graph, we propose a new evaluation metric GRADE, which stands for Graph-enhanced Representations for Automatic Dialogue Evaluation. Specifically , GRADE incorporates both coarse-grained utterance-level contextualized representations and fine-grained topic-level graph representations to evaluate dialogue coherence. The graph representations are obtained by reasoning over topic-level dialogue graphs enhanced with the evidence from a common-sense graph, including k-hop neighboring representations and hop-attention weights. Experimental results show that our GRADE significantly outperforms other state-of-the-art met-rics on measuring diverse dialogue models in terms of the Pearson and Spearman correlations with human judgements. Besides, we release a new large-scale human evaluation benchmark to facilitate future research on automatic metrics.}}, 
pages = {9230--9240}
}
@article{undefined, 
title = {{Learning to Write with Cooperative Discriminators}}, 
author = {Ari, Holtzman, and Jan, Buys, and Maxwell, Forbes, and Antoine, Bosselut, and David, Golub, and Yejin, Choi,}, 
journal = {ACL 2018 - 56th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)}, 
url = {https://arxiv.org/abs/1805.06087v1}, 
abstract = {{Recurrent Neural Networks (RNNs) are powerful autoregressive sequence models,but when used to generate natural language their output tends to be overlygeneric, repetitive, and self-contradictory. We postulate that the objectivefunction optimized by RNN language models, which amounts to the overallperplexity of a text, is not expressive enough to capture the notion ofcommunicative goals described by linguistic principles such as Grice's Maxims.We propose learning a mixture of multiple discriminative models that can beused to complement the RNN generator and guide the decoding process. Humanevaluation demonstrates that text generated by our system is preferred overthat of baselines by a large margin and significantly enhances the overallcoherence, style, and information content of the generated text.}}, 
year = {2018}, 
pages = {1638--1649}, 
volume = {1}
}
@inproceedings{undefined, 
keywords = {German Audiobooks,Speech Recognition,Spoken Language Translation}, 
author = {B., Beilharz, and X., Sun, and S., Karimova, and S., Riezler,}, 
title = {{LibriVoxDeEn: A corpus for German-to-english speech translation and German speech recognition}}, 
isbn = {9791095546344}, 
abstract = {{We present a corpus of sentence-aligned triples of German audio, German text, and English translation, based on German audio books. The speech translation data consist of 110 hours of audio material aligned to over 50k parallel sentences. An even larger dataset comprising 547 hours of German speech aligned to German text is available for speech recognition. The audio data is read speech and thus low in disfluencies. The quality of audio and sentence alignments has been checked by a manual evaluation, showing that speech alignment quality is in general very high. The sentence alignment quality is comparable to well-used parallel translation data and can be adjusted by cutoffs on the automatic alignment score. To our knowledge, this corpus is to date the largest resource for German speech recognition and for end-to-end German-to-English speech translation.}}
}
@inproceedings{10.1145/3442381, 
year = {2021}, 
keywords = {entity tracking,external memory,memory network,mental state representation,narrative comprehension,natural language generation,pragmatics,representation learning,social commonsense Knowledge,social events}, 
author = {Prashanth, Vijayaraghavan, and Deb, Roy,}, 
title = {{Modeling Human Motives and Emotions from Personal Narratives Using External Knowledge And Entity Tracking; Modeling Human Motives and Emotions from Personal Narratives Using External Knowledge And Entity Tracking}}, 
isbn = {9781450383127}, 
doi = {10.1145/3442381}, 
url = {https://doi.org/10.1145/3442381.3449997}, 
abstract = {{The ability to automatically understand and infer characters' motivations and emotional states is key to better narrative comprehension. In this work, we propose a Transformer-based architecture, referred to as Nemo, to model characters' motives and emotions from personal narratives. Towards this goal, we incorporate social commonsense knowledge about the mental states of people related to social events and employ dynamic state tracking of entities using an augmented memory module. Our model learns to produce con-textual embeddings and explanations of characters' mental states by integrating external knowledge along with prior narrative context and mental state encodings. We leverage weakly-annotated personal narratives and knowledge data to train our model and demonstrate its effectiveness on publicly available StoryCommonsense dataset containing annotations for character mental states. Further, we show that the learned mental state embeddings can be applied in downstream tasks such as empathetic response generation.}}, 
pages = {529--540}, 
volume = {12}, 
series = {Proceedings of the Web Conference 2021}, 
publisher = {ACM}
}
@article{undefined, 
title = {{Moral Stories: Situated Reasoning about Norms, Intents, Actions, and their Consequences}}, 
author = {Denis, Emelin, and Le, Bras, Ronan and D., Hwang, Jena and Maxwell, Forbes, and Yejin, Choi,}, 
journal = {arXiv}, 
url = {https://arxiv.org/abs/2012.15738v1}, 
abstract = {{In social settings, much of human behavior is governed by unspoken rules ofconduct. For artificial systems to be fully integrated into socialenvironments, adherence to such norms is a central prerequisite. We investigatewhether contemporary NLG models can function as behavioral priors for systemsdeployed in social settings by generating action hypotheses that achievepredefined goals under moral constraints. Moreover, we examine if models cananticipate likely consequences of (im)moral actions, or explain why certainactions are preferable by generating relevant norms. For this purpose, weintroduce 'Moral Stories', a crowd-sourced dataset of structured, branchingnarratives for the study of grounded, goal-oriented social reasoning. Finally,we propose decoding strategies that effectively combine multiple expert modelsto significantly improve the quality of generated actions, consequences, andnorms compared to strong baselines, e.g. though abductive reasoning.}}, 
year = {2020}
}
@article{undefined, 
year = {2021}, 
title = {{Not All Attention Is All You Need}}, 
author = {Wu, Hongqiu and Zhao, Hai and Zhang, Min}, 
journal = {arXiv}, 
eprint = {2104.04692}, 
abstract = {{Beyond the success story of pre-trained language models (PrLMs) in recent natural language processing, they are susceptible to over-fitting due to unusual large model size. To this end, dropout serves as a therapy. However, existing methods like random-based, knowledge-based and search-based dropout are more general but less effective onto self-attention based models, which are broadly chosen as the fundamental architecture of PrLMs. In this paper, we propose a novel dropout method named AttendOut to let self-attention empowered PrLMs capable of more robust task-specific tuning. We demonstrate that state-of-the-art models with elaborate training design may achieve much stronger results. We verify the universality of our approach on extensive natural language processing tasks.}}
}
@inproceedings{undefined, 
author = {Sumanth, Dathathri, and Andrea, Madotto, and Janice, Lan, and Jane, Hung, and Uber, Ai, and Eric, Frank, and Piero, Molino, and Jason, Yosinski, and Rosanne, Liu,}, 
title = {{PLUG AND PLAY LANGUAGE MODELS: A SIMPLE APPROACH TO CONTROLLED TEXT GENERATION}}, 
url = {https://github.com/uber-research/PPLM.}, 
abstract = {{Large transformer-based language models (LMs) trained on huge text corpora have shown unparalleled generation capabilities. However, controlling attributes of the generated language (e.g. switching topic or sentiment) is difficult without modifying the model architecture or fine-tuning on attribute-specific data and entailing the significant cost of retraining. We propose a simple alternative: the Plug and Play Language Model (PPLM) for controllable language generation, which combines a pretrained LM with one or more simple attribute classifiers that guide text generation without any further training of the LM. In the canonical scenario we present, the attribute models are simple classifiers consisting of a user-specified bag of words or a single learned layer with 100,000 times fewer parameters than the LM. Sampling entails a forward and backward pass in which gradients from the attribute model push the LM's hidden activations and thus guide the generation. Model samples demonstrate control over a range of topics and sentiment styles, and extensive automated and human annotated evaluations show attribute alignment and fluency. PPLMs are flexible in that any combination of differen-tiable attribute models may be used to steer text generation, which will allow for diverse and creative applications beyond the examples given in this paper.}}
}
@article{undefined, 
keywords = {Deep Learning,Reinforcement Learning,Unsupervised Learning}, 
title = {{SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient}}, 
author = {Lantao, Yu, and Weinan, Zhang, and Jun, Wang, and Yong, Yu,}, 
journal = {Proceedings of the AAAI Conference on Artificial Intelligence}, 
url = {https://ojs.aaai.org/index.php/AAAI/article/view/10804}, 
abstract = {{As a new way of training generative models, Generative Adversarial Net (GAN) that uses a discriminative model to guide the training of the generative model has enjoyed considerable success in generating real-valued data. However, it has limitations when the goal is for generating sequences of discrete tokens. A major reason lies in that the discrete outputs from the generative model make it difficult to pass the gradient update from the discriminative model to the generative model. Also, the discriminative model can only assess a complete sequence, while for a partially generated sequence, it is non-trivial to balance its current score and the future one once the entire sequence has been generated. In this paper, we propose a sequence generation framework, called SeqGAN, to solve the problems. Modeling the data generator as a stochastic policy in reinforcement learning (RL), SeqGAN bypasses the generator differentiation problem by directly performing gradient policy update. The RL reward signal comes from the GAN discriminator judged on a complete sequence, and is passed back to the intermediate state-action steps using Monte Carlo search. Extensive experiments on synthetic data and real-world tasks demonstrate significant improvements over strong baselines.}}, 
year = {2017}, 
number = {1}, 
volume = {31}
}
@misc{undefined, 
author = {}, 
title = {{Social Chemistry}}, 
url = {https://maxwellforbes.com/social-chemistry/}
}
@article{undefined, 
title = {{Social Chemistry 101: Learning to Reason about Social and Moral Norms}}, 
author = {Maxwell, Forbes, and D., Hwang, Jena and Vered, Shwartz, and Maarten, Sap, and Yejin, Choi,}, 
journal = {EMNLP}, 
url = {http://arxiv.org/abs/2011.00620}, 
abstract = {{Social norms -- the unspoken commonsense rules about acceptable social behavior -- are crucial in understanding the underlying causes and intents of people's actions in narratives. For example, underlying an action such as "wanting to call cops on my neighbors" are social norms that inform our conduct, such as "It is expected that you report crimes." We present Social Chemistry, a new conceptual formalism to study people's everyday social norms and moral judgments over a rich spectrum of real life situations described in natural language. We introduce Social-Chem-101, a large-scale corpus that catalogs 292k rules-of-thumb such as "it is rude to run a blender at 5am" as the basic conceptual units. Each rule-of-thumb is further broken down with 12 different dimensions of people's judgments, including social judgments of good and bad, moral foundations, expected cultural pressure, and assumed legality, which together amount to over 4.5 million annotations of categorical labels and free-text descriptions. Comprehensive empirical results based on state-of-the-art neural models demonstrate that computational modeling of social norms is a promising research direction. Our model framework, Neural Norm Transformer, learns and generalizes Social-Chem-101 to successfully reason about previously unseen situations, generating relevant (and potentially novel) attribute-aware social rules-of-thumb.}}, 
year = {2020}, 
pages = {653--670}
}
@inproceedings{undefined, 
author = {Maarten, Sap, and Hannah, Rashkin, and Derek, Chen, and Ronan, Le Bras, and Yejin, Choi,}, 
title = {{Social IQA: Commonsense reasoning about social interactions}}, 
abstract = {{We introduce SOCIAL IQA, the first large-scale benchmark for commonsense reasoning about social situations. SOCIAL IQA contains 38,000 multiple choice questions for probing emotional and social intelligence in a variety of everyday situations (e.g., Q: ‚ÄúJordan wanted to tell Tracy a secret, so Jordan leaned towards Tracy. Why did Jordan do this?‚Äù A: ‚ÄúMake sure no one else could hear‚Äù). Through crowdsourcing, we collect commonsense questions along with correct and incorrect answers about social interactions, using a new framework that mitigates stylistic artifacts in incorrect answers by asking workers to provide the right answer to a different but related question. Empirical results show that our benchmark is challenging for existing question-answering models based on pretrained language models, compared to human performance (>20\% gap). Notably, we further establish SOCIAL IQA as a resource for transfer learning of commonsense knowledge, achieving state-of-the-art performance on multiple commonsense reasoning tasks (Winograd Schemas, COPA).}}, 
pages = {4463--4473}, 
publisher = {Association for Computational Linguistics}
}
@article{undefined, 
title = {{SocialIQA: Commonsense Reasoning about Social Interactions}}, 
author = {Maarten, Sap, and Hannah, Rashkin, and Derek, Chen, and Ronan, LeBras, and Yejin, Choi,}, 
journal = {EMNLP-IJCNLP 2019 - 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing, Proceedings of the Conference}, 
url = {http://arxiv.org/abs/1904.09728}, 
abstract = {{We introduce Social IQa, the first largescale benchmark for commonsense reasoning about social situations. Social IQa contains 38,000 multiple choice questions for probing emotional and social intelligence in a variety of everyday situations (e.g., Q: "Jordan wanted to tell Tracy a secret, so Jordan leaned towards Tracy. Why did Jordan do this?" A: "Make sure no one else could hear"). Through crowdsourcing, we collect commonsense questions along with correct and incorrect answers about social interactions, using a new framework that mitigates stylistic artifacts in incorrect answers by asking workers to provide the right answer to a different but related question. Empirical results show that our benchmark is challenging for existing question-answering models based on pretrained language models, compared to human performance (>20\% gap). Notably, we further establish Social IQa as a resource for transfer learning of commonsense knowledge, achieving state-of-the-art performance on multiple commonsense reasoning tasks (Winograd Schemas, COPA).}}, 
year = {2019}, 
pages = {4463--4473}
}
@inproceedings{undefined, 
author = {Mikael, Henaff, and Jason, Weston, and Arthur, Szlam, and Antoine, Bordes, and Yann, LeCun,}, 
title = {{Tracking the world state with recurrent entity networks}}, 
abstract = {{We introduce a new model, the Recurrent Entity Network (EntNet). It is equipped with a dynamic long-term memory which allows it to maintain and update a representation of the state of the world as it receives new data. For language understanding tasks, it can reason on-the-fly as it reads text, not just when it is required to answer a question or respond as is the case for a Memory Network (Sukhbaatar et al., 2015). Like a Neural Turing Machine or Differentiable Neural Computer (Graves et al., 2014; 2016) it maintains a fixed size memory and can learn to perform location and content-based read and write operations. However, unlike those models it has a simple parallel architecture in which several memory locations can be updated simultaneously. The EntNet sets a new state-of-the-art on the bAbI tasks, and is the first method to solve all the tasks in the 10k training examples setting. We also demonstrate that it can solve a reasoning task which requires a large number of supporting facts, which other methods are not able to solve, and can generalize past its training horizon. It can also be practically used on large scale datasets such as Children's Book Test, where it obtains competitive performance, reading the story in a single pass.}}, 
publisher = {International Conference on Learning Representations, ICLR}
}